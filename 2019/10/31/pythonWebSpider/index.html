<!DOCTYPE html>

<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=0">

  <meta name="description" content="背景之前零零碎碎接触过几次爬虫，有的是公开课，有的是实体课。老师都是偏实践，对于理论的部分都是一笔带过，所以对于那些库都是一知半解。自己也想写一些东西，尽可能在吸收那些大佬的总结的同时，加入一些自己的理解。把大佬一越而过，而我们要挣扎很久的坑铺平。
这样学的知识更像是一盘散沙，我会简单地使用这些函数">


<link rel="alternate" href="/atom.xml" title="Aaron Lin" type="application/atom+xml">
<meta name="theme-color" content="#a1d0f6">
<title>爬虫是咋回事 - Aaron Lin</title>
<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->


<!-- <link rel="shortcut icon" href="/favicon.png"> -->

<link rel="shortcut icon" href="/favicon.ico">
<link rel="stylesheet" href="/css/style.css">
<nav class="main-nav">
	
	    <a href="/">← 主页</a>
	
	
	    <a href="/about/">关于</a>
	
	    <a href="/archives/">归档</a>
	
	<a class="cta" href="/rss2.xml" data-no-instant>订阅</a>
</nav>

<section id="wrapper">
    <article class="post">
    <header>
        
            <h1>爬虫是咋回事</h1>
        
        <h2 class="headline">Oct 31 2019
        
            
            <a href="/categories/Python笔记/#Python笔记">Python笔记</a>
        
        </h2>
    </header>
</article>
<section id="post-body"><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>之前零零碎碎接触过几次爬虫，有的是公开课，有的是实体课。老师都是偏实践，对于理论的部分都是一笔带过，所以对于那些库都是一知半解。自己也想写一些东西，尽可能在吸收那些大佬的总结的同时，加入一些自己的理解。把大佬一越而过，而我们要挣扎很久的坑铺平。</p>
<p>这样学的知识更像是一盘散沙，我会简单地使用这些函数去实现一些功能，但却不清楚它们之间的关系，遇到一些复杂的问题就很难去处理。系统地学习虽然比较耗时，但是会对整个体系有个了解，而这在你遇到一些问题的时候会发挥重要作用。</p>
<p>网上教程的质量参差不齐，而且代码案例爬取的网站的结构也可能随着时间的推移而改变，对于初学者来说是个不小的挑战。</p>
<p>我看的是嵩天老师的<a href="https://www.icourse163.org/learn/BIT-1001870001" target="_blank" rel="noopener">Python网络爬虫与信息提取</a>，嵩天老师讲的比较通俗易懂，不需要有特别扎实的Python基础也能听懂。</p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><ul>
<li>爬取网页，程序没有反应：可能是网络连接问题，可以用通用代码架构来提高爬虫的可靠性</li>
<li>F12开发者工具-Network选项卡里可以看的文本但是爬取的文本却没有：网站防爬机制，可以定义Headers,Cookie等解决</li>
</ul>
<h2 id="爬虫原理"><a href="#爬虫原理" class="headerlink" title="爬虫原理"></a>爬虫原理</h2><p>对于非异步加载的网站，一般都可以通过requests库和BeautifulSoup库爬取信息</p>
<ol>
<li>获取网页的源代码：通过Requests库，来获取网页的HTML代码</li>
<li>解析网页代码获得期望的数据：通过BeautifulSoup库解析网页源代码，把我们需要的信息按照一定规则提取出来<h2 id="requests库"><a href="#requests库" class="headerlink" title="requests库"></a>requests库</h2>requests库有7个主要方法，后6个方法都是对request方法的封装（使用更方便）</li>
</ol>
<p><img src="/2019/10/31/pythonWebSpider/1.png" alt="嵩天"></p>
<p>6个方法对应的就是HTTP协议对资源的操作</p>
<p><img src="/2019/10/31/pythonWebSpider/2.png" alt="嵩天"></p>
<p>HTTP请求状态：status_code 200表示成功，返回其他值说明连接出现问题</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(url) <span class="comment">#url传入爬取的网址</span></span><br><span class="line">print(r.status_code)  <span class="comment">#200表示连接成功</span></span><br></pre></td></tr></table></figure>
<p>爬虫通用框架：网络连接可能出现各种异常，所以我们可以用try-except处理异常，增强代码可靠性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  <span class="comment"># 导入requests库，用于获得网页源代码</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>) <span class="comment"># 设置超时时间为30毫秒</span></span><br><span class="line">        r.raise_for_status() <span class="comment"># 这个方法就是判断status_code是否为200，否的话引发HTTPError异常</span></span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text <span class="comment"># 返回爬取到的文本</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></span><br></pre></td></tr></table></figure>

<p>编码：如果header没有chartset指定编码，默认就是ISO-8859-1，这个编码不能解析中文，可能会出现乱码，而apparent_encoding会根据内容猜测编码，所以我们一般把编码设置为apparent_encoding</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r.encoding = r.apparent_encoding</span><br></pre></td></tr></table></figure>
<h2 id="BeautifulSoup库"><a href="#BeautifulSoup库" class="headerlink" title="BeautifulSoup库"></a>BeautifulSoup库</h2><p>BeautifulSoup使用pip安装要注意，如果没有加末尾的4，实际安装的是BeautifulSoup3 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip insatll beautifulsoup4</span><br></pre></td></tr></table></figure>
<p>在import的时候也要注意，从bs4库(beautifulsoup4)中引入BeautifulSoup这个类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#注意B和S是大写</span></span><br></pre></td></tr></table></figure>
<p>创建一个BeautifulSoup对象，传入的一个参数是需要解析的HTML或者XML文档，第二个参数是使用的解析器，这里需要lxml，需要安装一下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install lxml</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br></pre></td></tr></table></figure>

<p>BeautifulSoup类的基本元素：</p>
<ul>
<li>Tag：标签，HTML中由&lt;&gt;和&lt;/&gt;构成的那些标签</li>
<li>Name：就是标签的名字，a标签、p标签</li>
<li>Attributes：标签的属性</li>
<li>NavigableString：标签的&lt;&gt;和&lt;/&gt;之间的文字</li>
<li>Comment：HTML中的注释 </li>
</ul>
<p>爬取数据需要先找到数据对应Tag标签，而Name,Attributes,NavigableString,Comment就是围绕着Tag标签，Comment相对来说用的少</p>
<p>HTML标签树遍历：</p>
<ul>
<li>下行遍历：.contents  .children  .descendants</li>
<li>上行遍历：.parent  .parents</li>
<li>平行遍历：.next_sibling  .next_siblings  .previous_sibling  .previous_sibling</li>
</ul>
<p>有复数含义的属性返回的都是列表，而像.parent .next_sibling  .previous_sibling 这些都是返回一个Tag标签节点 &lt;class ‘bs4.element.Tag’&gt; 或者是一个字符串节点（有可能是\n）,在遍历这些列表的时候如果没有判断类型，使用的时候可能会报错</p>
<blockquote>
<p>TypeError: ‘NavigableString’ object is not callable</p>
</blockquote>
<p>find_all( )方法：</p>
<ul>
<li>可检索标签名、标签属性、标签内的字符串，返回一个列表</li>
<li>还有find( ),find_parent( ),find_parents( )等方法</li>
<li>因为dind_all比较常用，所以对象是Tag或者是soup都可以省略find_all,<tag>find_all(…)等价于<tag>(…),soup.find_all(..)等价于soup(…)<h2 id="爬取大学排名实例"><a href="#爬取大学排名实例" class="headerlink" title="爬取大学排名实例"></a>爬取大学排名实例</h2>爬取最好大学网的大学排名数据，将排名、学校名称、地区输出到屏幕</tag></tag></li>
</ul>
<p><img src="/2019/10/31/pythonWebSpider/3.png" alt="爬取大学排名效果"></p>
<h3 id="遇到的问题-1"><a href="#遇到的问题-1" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><ul>
<li>遍历每个tr获取每个大学信息，出现object is not callable</li>
<li>输出到屏幕排版问题</li>
</ul>
<h3 id="分析网页结构"><a href="#分析网页结构" class="headerlink" title="分析网页结构"></a>分析网页结构</h3><p>Chrome浏览器打开<a href="http://zuihaodaxue.com/zuihaodaxuepaiming2019.html" target="_blank" rel="noopener">最好大学网的网页</a>，按F12打开开发者工具</p>
<p><img src="/2019/10/31/pythonWebSpider/4.png" alt="Chrome开发者工具"></p>
<p>需要刷新一下网页才会显示，双击这个document文件</p>
<p><img src="/2019/10/31/pythonWebSpider/5.png" alt="Document文件"></p>
<p>选择Response选项卡就可以看到HTML代码，全选复制到编辑器里</p>
<p><img src="/2019/10/31/pythonWebSpider/6.png" alt="VScode"></p>
<p>排名的信息在tbody标签里，每一个tr标签里面都是一所大学的信息，每一个td标签就是每所大学具体的信息。我们可以遍历tbody里面的每个tr标签，然后把每所大学的信息都保存在list里。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr, bs4.element.Tag):</span><br><span class="line">            <span class="comment"># import bs4 才能使用对应的标签定义</span></span><br><span class="line">            tds = tr(<span class="string">'td'</span>)  <span class="comment"># 查询tr 中的td标签</span></span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string, tds[<span class="number">1</span>].string, tds[<span class="number">2</span>].string])</span><br></pre></td></tr></table></figure>

<p>在遍历的时候报错,会遇到一个问题：</p>
<blockquote>
<p>发生异常: TypeError’NavigableString’ object is not callable</p>
</blockquote>
<p><img src="/2019/10/31/pythonWebSpider/7.png" alt="comment"></p>
<p>原因是：HTML代码tbody标签中最后有一段Comment,而Comment对象和NavigableString对象不能像Tag对象一样被调用，所以我们在遍历时需要对类型进行判断，判断是否为：bs4.element.Tag</p>
<h3 id="排版问题"><a href="#排版问题" class="headerlink" title="排版问题"></a>排版问题</h3><p>在输出时候中文排版会出现一些小问题<br><img src="/2019/10/31/pythonWebSpider/8.png" alt="排版错误"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>]))</span><br></pre></td></tr></table></figure>

<p>原因就是我们在使用format方法在我们定义好的布局里填充大学信息的时候，排版默认使用西文的空格，这样会导致排版错误。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    tplt = <span class="string">"&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>, chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="comment"># 使用中文空格填充</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        <span class="comment"># print(u)</span></span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br></pre></td></tr></table></figure>

<p>我们可以使用中文空格来进行填充，这样可以解决排版问题，chr(12288)就是中文空格</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tplt = <span class="string">"&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;"</span></span><br><span class="line">print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个tplt就是我们定义每行的模板，&#123;&#125;里面就是要填充的内容</span></span><br><span class="line"><span class="comment"># 冒号前面是填充内容的索引号，^10 ^的表居中对齐10代表宽度为10</span></span><br><span class="line"><span class="comment"># \t 表示一个制表符，在冒号后面是填充字符，不指定默认使用西文空格</span></span><br><span class="line"><span class="comment"># 这里我们指定&#123;3&#125;,就是使用索引为3的 chr(12288) 来填充</span></span><br></pre></td></tr></table></figure>


<h3 id="具体代码"><a href="#具体代码" class="headerlink" title="具体代码"></a>具体代码</h3><p>先把大体的框架写完</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillUnivList</span><span class="params">(ulist, html)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">'http://zuihaodaxue.com/zuihaodaxuepaiming2019.html'</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    fillUnivList(uinfo, html)</span><br><span class="line">    printUnivList(uinfo, <span class="number">20</span>)  <span class="comment"># 爬取前20名</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

<p>再填充每个具体的方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillUnivList</span><span class="params">(ulist, html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr, bs4.element.Tag):</span><br><span class="line">            <span class="comment"># import bs4 才能使用对应的标签定义</span></span><br><span class="line">            tds = tr(<span class="string">'td'</span>)  <span class="comment"># 查询tr 中的td标签</span></span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string, tds[<span class="number">1</span>].string, tds[<span class="number">2</span>].string])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># def printUnivList(ulist, num):</span></span><br><span class="line"><span class="comment">#     print("&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;".format("排名", "学校名称", "总分"))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     for i in range(num):</span></span><br><span class="line"><span class="comment">#         u = ulist[i]</span></span><br><span class="line"><span class="comment">#         print("&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;".format(u[0], u[1], u[2]))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    tplt = <span class="string">"&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>, chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="comment"># 使用中文空格填充</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        <span class="comment"># print(u)</span></span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">'http://zuihaodaxue.com/zuihaodaxuepaiming2019.html'</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    fillUnivList(uinfo, html)</span><br><span class="line">    printUnivList(uinfo, <span class="number">20</span>) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure></section>
    
        
        <h2 class="footline">
            <a href="/tags/Python/#Python">Python</a>, <a href="/tags/爬虫/#爬虫">爬虫</a>
        </h2>
    

    <footer id="post-meta" class="clearfix">
        <a href="/about/">
        <img class="avatar" src="/images/avatar.jpg">
        <div>
            <span class="dark">Aaron Lin</span>
            <span></span>
        </div>
        </a>
        <section id="sharing">
            <a title="Share to Twitter" class="twitter" href="https://twitter.com/intent/tweet?text=https://aaronlinv.github.io/2019/10/31/pythonWebSpider/ - 爬虫是咋回事 @" target="_blank" rel="noopener"><span class="icon-twitter">tweet</span></a>
            <a title="Share to Facebook" class="facebook" href="#" onclick="
                window.open(
                  'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
                  'facebook-share-dialog',
                  'width=626,height=436');
                return false;"><span class="icon-facebook-sign">Share</span>
            </a>
        </section>
    </footer>


  <section id="comment">
    <button class="btn" id="loadcmts" onclick="cmts.load();">加载评论</button>
    <div id="gitment"></div>
    <script src='/js/gitment.browser.js'></script>
    <link rel="stylesheet" href=''>
    <script>
      var cmts={
        load:function cmts(){
          var gitment = new Gitment({
          
            id: "爬虫是咋回事",
          
            owner: "",
            repo: "",
            oauth: {
              client_id: "",
              client_secret: "",
            },
          })
          gitment.render('gitment');
          var loadcmt = document.getElementById("loadcmts");
          var imyourfather = loadcmt.parentNode;
          imyourfather.removeChild(loadcmts)
        }
      }
    </script>
  </section>


	<footer id="footer">
    <div id="social">
        <p class="small">©
            Aaron Lin | Powered by Hexo &
                <a href="https://github.com/F0r3at/Lights" target="_blank" rel="noopener"> Lights</a>
        </p>
    </div>
</footer>
</section>

	<script src="//cdnjs.loli.net/ajax/libs/instantclick/3.0.1/instantclick.min.js" data-no-instant></script>
	<script data-no-instant>
		
		InstantClick.init('mousedown');
	</script>



