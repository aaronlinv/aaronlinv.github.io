<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Aaron Lin</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-11-07T16:06:05.108Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Aaron Lin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>爬虫是咋回事</title>
    <link href="http://yoursite.com/2019/10/31/pythonWebSpider/"/>
    <id>http://yoursite.com/2019/10/31/pythonWebSpider/</id>
    <published>2019-10-31T08:46:19.000Z</published>
    <updated>2019-11-07T16:06:05.108Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>之前零零碎碎接触过几次爬虫，有的是公开课，有的是实体课。老师都是偏实践，对于理论的部分都是一笔带过，所以对于那些库都是一知半解。自己也想写一些东西，尽可能在吸收那些大佬的总结的同时，加入一些自己的理解。把大佬一越而过，而我们要挣扎很久的坑铺平。</p><p>这样学的知识更像是一盘散沙，我会简单地使用这些函数去实现一些功能，但却不清楚它们之间的关系，遇到一些复杂的问题就很难去处理。系统地学习虽然比较耗时，但是会对整个体系有个了解，而这在你遇到一些问题的时候会发挥重要作用。</p><p>网上教程的质量参差不齐，而且代码案例爬取的网站的结构也可能随着时间的推移而改变，对于初学者来说是个不小的挑战。</p><p>我看的是嵩天老师的<a href="https://www.icourse163.org/learn/BIT-1001870001" target="_blank" rel="noopener">Python网络爬虫与信息提取</a>，嵩天老师讲的比较通俗易懂，不需要有特别扎实的Python基础也能听懂。</p><h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><ul><li>爬取网页，程序没有反应：可能是网络连接问题，可以用通用代码架构来提高爬虫的可靠性</li><li>F12开发者工具-Network选项卡里可以看的文本但是爬取的文本却没有：网站防爬机制，可以定义Headers,Cookie等解决</li></ul><h2 id="爬虫原理"><a href="#爬虫原理" class="headerlink" title="爬虫原理"></a>爬虫原理</h2><p>对于非异步加载的网站，一般都可以通过requests库和BeautifulSoup库爬取信息</p><ol><li>获取网页的源代码：通过Requests库，来获取网页的HTML代码</li><li>解析网页代码获得期望的数据：通过BeautifulSoup库解析网页源代码，把我们需要的信息按照一定规则提取出来<h2 id="requests库"><a href="#requests库" class="headerlink" title="requests库"></a>requests库</h2>requests库有7个主要方法，后6个方法都是对request方法的封装（使用更方便）</li></ol><p><img src="./1.png" alt="嵩天"></p><p>6个方法对应的就是HTTP协议对资源的操作</p><p><img src="./2.png" alt="嵩天"></p><p>HTTP请求状态：status_code 200表示成功，返回其他值说明连接出现问题</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(url) <span class="comment">#url传入爬取的网址</span></span><br><span class="line">print(r.status_code)  <span class="comment">#200表示连接成功</span></span><br></pre></td></tr></table></figure><p>爬虫通用框架：网络连接可能出现各种异常，所以我们可以用try-except处理异常，增强代码可靠性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  <span class="comment"># 导入requests库，用于获得网页源代码</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>) <span class="comment"># 设置超时时间为30毫秒</span></span><br><span class="line">        r.raise_for_status() <span class="comment"># 这个方法就是判断status_code是否为200，否的话引发HTTPError异常</span></span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text <span class="comment"># 返回爬取到的文本</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></span><br></pre></td></tr></table></figure><p>编码：如果header没有chartset指定编码，默认就是ISO-8859-1，这个编码不能解析中文，可能会出现乱码，而apparent_encoding会根据内容猜测编码，所以我们一般把编码设置为apparent_encoding</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r.encoding = r.apparent_encoding</span><br></pre></td></tr></table></figure><h2 id="BeautifulSoup库"><a href="#BeautifulSoup库" class="headerlink" title="BeautifulSoup库"></a>BeautifulSoup库</h2><p>BeautifulSoup使用pip安装要注意，如果没有加末尾的4，实际安装的是BeautifulSoup3 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip insatll beautifulsoup4</span><br></pre></td></tr></table></figure><p>在import的时候也要注意，从bs4库(beautifulsoup4)中引入BeautifulSoup这个类</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#注意B和S是大写</span></span><br></pre></td></tr></table></figure><p>创建一个BeautifulSoup对象，传入的一个参数是需要解析的HTML或者XML文档，第二个参数是使用的解析器，这里需要lxml，需要安装一下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install lxml</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br></pre></td></tr></table></figure><p>BeautifulSoup类的基本元素：</p><ul><li>Tag：标签，HTML中由&lt;&gt;和&lt;/&gt;构成的那些标签</li><li>Name：就是标签的名字，a标签、p标签</li><li>Attributes：标签的属性</li><li>NavigableString：标签的&lt;&gt;和&lt;/&gt;之间的文字</li><li>Comment：HTML中的注释 </li></ul><p>爬取数据需要先找到数据对应Tag标签，而Name,Attributes,NavigableString,Comment就是围绕着Tag标签，Comment相对来说用的少</p><p>HTML标签树遍历：</p><ul><li>下行遍历：.contents  .children  .descendants</li><li>上行遍历：.parent  .parents</li><li>平行遍历：.next_sibling  .next_siblings  .previous_sibling  .previous_sibling</li></ul><p>有复数含义的属性返回的都是列表，而像.parent .next_sibling  .previous_sibling 这些都是返回一个Tag标签节点 &lt;class ‘bs4.element.Tag’&gt; 或者是一个字符串节点（有可能是\n）,在遍历这些列表的时候如果没有判断类型，使用的时候可能会报错</p><blockquote><p>TypeError: ‘NavigableString’ object is not callable</p></blockquote><p>find_all( )方法：</p><ul><li>可检索标签名、标签属性、标签内的字符串，返回一个列表</li><li>还有find( ),find_parent( ),find_parents( )等方法</li><li>因为dind_all比较常用，所以对象是Tag或者是soup都可以省略find_all,<tag>find_all(…)等价于<tag>(…),soup.find_all(..)等价于soup(…)<h2 id="爬取大学排名实例"><a href="#爬取大学排名实例" class="headerlink" title="爬取大学排名实例"></a>爬取大学排名实例</h2>爬取最好大学网的大学排名数据，将排名、学校名称、地区输出到屏幕</li></ul><p><img src="./3.png" alt="爬取大学排名效果"></p><h3 id="遇到的问题-1"><a href="#遇到的问题-1" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><ul><li>遍历每个tr获取每个大学信息，出现object is not callable</li><li>输出到屏幕排版问题</li></ul><h3 id="分析网页结构"><a href="#分析网页结构" class="headerlink" title="分析网页结构"></a>分析网页结构</h3><p>Chrome浏览器打开<a href="http://zuihaodaxue.com/zuihaodaxuepaiming2019.html" target="_blank" rel="noopener">最好大学网的网页</a>，按F12打开开发者工具</p><p><img src="./4.png" alt="Chrome开发者工具"></p><p>需要刷新一下网页才会显示，双击这个document文件</p><p><img src="./5.png" alt="Document文件"></p><p>选择Response选项卡就可以看到HTML代码，全选复制到编辑器里</p><p><img src="./6.png" alt="VScode"></p><p>排名的信息在tbody标签里，每一个tr标签里面都是一所大学的信息，每一个td标签就是每所大学具体的信息。我们可以遍历tbody里面的每个tr标签，然后把每所大学的信息都保存在list里。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr, bs4.element.Tag):</span><br><span class="line">            <span class="comment"># import bs4 才能使用对应的标签定义</span></span><br><span class="line">            tds = tr(<span class="string">'td'</span>)  <span class="comment"># 查询tr 中的td标签</span></span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string, tds[<span class="number">1</span>].string, tds[<span class="number">2</span>].string])</span><br></pre></td></tr></table></figure><p>在遍历的时候报错,会遇到一个问题：</p><blockquote><p>发生异常: TypeError’NavigableString’ object is not callable</p></blockquote><p><img src="./7.png" alt="comment"></p><p>原因是：HTML代码tbody标签中最后有一段Comment,而Comment对象和NavigableString对象不能像Tag对象一样被调用，所以我们在遍历时需要对类型进行判断，判断是否为：bs4.element.Tag</p><h3 id="排版问题"><a href="#排版问题" class="headerlink" title="排版问题"></a>排版问题</h3><p>在输出时候中文排版会出现一些小问题<br><img src="./8.png" alt="排版错误"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>]))</span><br></pre></td></tr></table></figure><p>原因就是我们在使用format方法在我们定义好的布局里填充大学信息的时候，排版默认使用西文的空格，这样会导致排版错误。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    tplt = <span class="string">"&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>, chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="comment"># 使用中文空格填充</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        <span class="comment"># print(u)</span></span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br></pre></td></tr></table></figure><p>我们可以使用中文空格来进行填充，这样可以解决排版问题，chr(12288)就是中文空格</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tplt = <span class="string">"&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;"</span></span><br><span class="line">print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个tplt就是我们定义每行的模板，&#123;&#125;里面就是要填充的内容</span></span><br><span class="line"><span class="comment"># 冒号前面是填充内容的索引好，^10 ^的表居中对齐10代表宽度为10</span></span><br><span class="line"><span class="comment"># \t 表示一个制表符，在冒号后面是填充字符，不指定默认使用西文空格</span></span><br><span class="line"><span class="comment"># 这里我们指定&#123;3&#125;,就是使用索引为3的 chr(12288) 来填充</span></span><br></pre></td></tr></table></figure><h3 id="具体代码"><a href="#具体代码" class="headerlink" title="具体代码"></a>具体代码</h3><p>先把大体的框架写完</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillUnivList</span><span class="params">(ulist, html)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">'http://zuihaodaxue.com/zuihaodaxuepaiming2019.html'</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    fillUnivList(uinfo, html)</span><br><span class="line">    printUnivList(uinfo, <span class="number">20</span>)  <span class="comment"># 爬取前20名</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure><p>再填充每个具体的方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillUnivList</span><span class="params">(ulist, html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr, bs4.element.Tag):</span><br><span class="line">            <span class="comment"># import bs4 才能使用对应的标签定义</span></span><br><span class="line">            tds = tr(<span class="string">'td'</span>)  <span class="comment"># 查询tr 中的td标签</span></span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string, tds[<span class="number">1</span>].string, tds[<span class="number">2</span>].string])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># def printUnivList(ulist, num):</span></span><br><span class="line"><span class="comment">#     print("&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;".format("排名", "学校名称", "总分"))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     for i in range(num):</span></span><br><span class="line"><span class="comment">#         u = ulist[i]</span></span><br><span class="line"><span class="comment">#         print("&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;".format(u[0], u[1], u[2]))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    tplt = <span class="string">"&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>, chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="comment"># 使用中文空格填充</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        <span class="comment"># print(u)</span></span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">'http://zuihaodaxue.com/zuihaodaxuepaiming2019.html'</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    fillUnivList(uinfo, html)</span><br><span class="line">    printUnivList(uinfo, <span class="number">20</span>) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;之前零零碎碎接触过几次爬虫，有的是公开课，有的是实体课。老师都是偏实践，对于理论的部分都是一笔带过，所以对于那些库都是一知半解。自己也想写一
      
    
    </summary>
    
    
      <category term="Python笔记" scheme="http://yoursite.com/categories/Python%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="爬虫" scheme="http://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2019/10/23/hello-world/"/>
    <id>http://yoursite.com/2019/10/23/hello-world/</id>
    <published>2019-10-23T12:23:50.000Z</published>
    <updated>2019-10-23T16:07:44.404Z</updated>
    
    <content type="html"><![CDATA[<h2 id="过往"><a href="#过往" class="headerlink" title="过往"></a>过往</h2><p>前一段时间发生了很多事，经历了一些变动，让我开始重新审视自己</p><p>大一大二似乎都在随波逐流，做着那些“优秀”的人都在做的事</p><p>到头来不过只是在重复地做着某些领域最简单的事</p><h2 id="当下"><a href="#当下" class="headerlink" title="当下"></a>当下</h2><p>走出舒适圈，和不同的人交流，了解不同的观点</p><p>一点一点地积累，用博客改变自己，也用博客记录自己的改变</p><p>希望自己能坚持下去，不管是写博客，还是其他喜欢的事</p><h2 id="关于博客"><a href="#关于博客" class="headerlink" title="关于博客"></a>关于博客</h2><blockquote><p>写博客是一种“写作式学习”</p><p>只要你坚持写下去几年，写Blog给你带来的收益超乎想象，这是积累的力量。</p><p>引用自 <a href="http://www.read.org.cn/html/2005-xie-bo-ke-shi-yi-zhong-xie-zuo-shi-xue-xi.html" target="_blank" rel="noopener">写博客是一种“写作式学习”</a></p></blockquote><p>搭这个博客的初心就是激励自己，多把时间花在有意义的事情上，深入地学习一些东西</p><p>用的是Hexo + Github Pages，相对那些即开即用的博客，我更享受折腾带来的乐趣</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;过往&quot;&gt;&lt;a href=&quot;#过往&quot; class=&quot;headerlink&quot; title=&quot;过往&quot;&gt;&lt;/a&gt;过往&lt;/h2&gt;&lt;p&gt;前一段时间发生了很多事，经历了一些变动，让我开始重新审视自己&lt;/p&gt;
&lt;p&gt;大一大二似乎都在随波逐流，做着那些“优秀”的人都在做的事&lt;/p&gt;
      
    
    </summary>
    
    
      <category term="零碎" scheme="http://yoursite.com/categories/%E9%9B%B6%E7%A2%8E/"/>
    
    
  </entry>
  
</feed>
